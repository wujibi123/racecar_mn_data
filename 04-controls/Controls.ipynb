{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST import all the necessary libraries and modules!\n",
    "import cv2               # import OpenCV\n",
    "import numpy as np       # import NumPy\n",
    "\n",
    "# import functions \n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "from utils import *    \n",
    "def crop(img, top, bottom):\n",
    "    imgCropped = np.zeros(img.shape, dtype=np.uint8)\n",
    "    imgCropped[top:bottom] += img[top:bottom]\n",
    "    return imgCropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Percentage: 1.27%\n",
      "(0, 0)\n",
      "(array([70, 45, 30]), array([125, 140, 215]))\n",
      "Line\n",
      "Match Percentage: 0.955%\n",
      "(0, 0)\n",
      "(array([70, 45, 30]), array([125, 140, 215]))\n",
      "Line\n",
      "Match Percentage: 4.14%\n",
      "(0, 0)\n",
      "(array([70, 45, 30]), array([125, 140, 215]))\n",
      "Line\n",
      "Match Percentage: 1.59%\n",
      "(0, 0)\n",
      "(array([70, 45, 30]), array([125, 140, 215]))\n",
      "Line\n",
      "Match Percentage: 3.82%\n",
      "(0, 0)\n",
      "(array([70, 45, 30]), array([125, 140, 215]))\n",
      "Line\n",
      "Match Percentage: 0.955%\n",
      "(0, 0)\n",
      "(array([70, 45, 30]), array([125, 140, 215]))\n",
      "Line\n",
      "Match Percentage: 2.23%\n",
      "(0, 0)\n",
      "(array([70, 45, 30]), array([125, 140, 215]))\n",
      "Line\n",
      "Match Percentage: 1.59%\n",
      "(0, 0)\n",
      "(array([70, 45, 30]), array([125, 140, 215]))\n",
      "Line\n",
      "Match Percentage: 1.91%\n",
      "(0, 0)\n",
      "(array([70, 45, 30]), array([125, 140, 215]))\n",
      "Line\n",
      "Match Percentage: 4.46%\n",
      "(0, 0)\n",
      "(array([70, 45, 30]), array([125, 140, 215]))\n",
      "Line\n",
      "Match Percentage: 4.14%\n"
     ]
    }
   ],
   "source": [
    "screen_center = 320\n",
    "def findGreatestContour(contours):\n",
    "    cnt = [-1, -1]\n",
    "    for i in range(0, len(contours)):\n",
    "        if (cv2.contourArea(contours[i]) >= cnt[1]):\n",
    "            cnt  = [i, cv2.contourArea(contours[i])]\n",
    "    return contours[cnt[0]]\n",
    "\n",
    "## need to define?\n",
    "def turn(angle): \n",
    "    print(angle)\n",
    "\n",
    "def getAngle2(x, y):\n",
    "    dist = cx - screen_center\n",
    "    \n",
    "    if dist is not 0:\n",
    "        ratio = dist/screen_center\n",
    "        angle = ratio*c \n",
    "    return angle \n",
    "    \n",
    "def getAngle(contour):\n",
    "    \n",
    "    M = cv2.moments(contour)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    \n",
    "    c = 15\n",
    "    angle, ratio = (0, 0)\n",
    "\n",
    "    dist = cx - screen_center\n",
    "\n",
    "    if dist is not 0:\n",
    "        ratio = dist/screen_center\n",
    "        angle = ratio*c \n",
    "    return angle \n",
    "\n",
    "def get_angle(x, error=0.5):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        1. box dimensions (list) --> x, y, w, h\n",
    "    output:\n",
    "        if 1 ft/more away:\n",
    "            1. an angle for the car to turn\n",
    "        else:\n",
    "            1. None\n",
    "    \"\"\" \n",
    "    ratio, angle, screen_center, c = (0, 0, 720.0, 2)\n",
    "    \n",
    "    dist = x - screen_center\n",
    "    if box_dist is not 0:\n",
    "        ratio = box_dist/screen_center \n",
    "    if abs(ratio) > error:\n",
    "        angle = ratio*constant\n",
    "    return angle\n",
    "\n",
    "def lineFollowing(img, colorRange, testing=False):\n",
    "    res =[None, None]\n",
    "    if testing:\n",
    "        res = [img, None]\n",
    "    # print(img)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, colorRange[0], colorRange[1])\n",
    "    # inv_mask = cv2.bitwise_not(mask)\n",
    "    ctImg, contours, __ = cv2.findContours(mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours == []:\n",
    "        res[-1] = \"empty contour list\"\n",
    "        return res\n",
    "    cnt = findGreatestContour(contours)\n",
    "    if cv2.contourArea(cnt) > 5:\n",
    "        res[-1] = \"contour area too small\"\n",
    "        return res \n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    center = (x+w/2, y+h/2)\n",
    "    if testing:\n",
    "        output = cv2.rectangle(img, (x,y),(x+w,y+h),(0,0, 255),2) \n",
    "        output = cv2.circle(output, center, 10, (0,0, 255), -1)\n",
    "        res[0] = output\n",
    "\n",
    "    angle = getAngle(cnt)\n",
    "    turn(angle)\n",
    "    return res \n",
    "\n",
    "def pathSelection(image, colorList):\n",
    "    image = crop(image, 100, 200)\n",
    "    for color in colorList:\n",
    "        output, angle = lineFollowing(image, color) \n",
    "        if angle is not None:\n",
    "            print(color)\n",
    "            return [output, angle]\n",
    "    return [image, -1]\n",
    "\n",
    "# green, yellow \n",
    "c = 15\n",
    "colorRange = [(np.array([70, 45, 30]), np.array([125, 140, 215])), \n",
    "             (np.array([0, 80, 95]), np.array([25, 200, 250]))]\n",
    "\n",
    "# showVideoAction(pathSelection, colorRange)\n",
    "\n",
    "############################################################################################################\n",
    "# Sign detection functions\n",
    "\n",
    "def getKeypoints(image, feature_detection_algorithm, hessianThreshold = 400):\n",
    "    '''\n",
    "    outputs keypoints and descriptions for the inputted image.\n",
    "    '''\n",
    "    global sift, surf, orb\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Create SIFT, SURF, or ORB objects\n",
    "    if feature_detection_algorithm=='sift':\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        kp, des = sift.detectAndCompute(image, None)\n",
    "\n",
    "    elif feature_detection_algorithm=='surf':\n",
    "        surf = cv2.xfeatures2d.SURF_create(hessianThreshold, extended=True)\n",
    "        kp, des = surf.detectAndCompute(image, None)\n",
    "\n",
    "    elif feature_detection_algorithm=='orb':\n",
    "        orb = cv2.ORB_create(nFeatures)\n",
    "        kp, des = orb.detectAndCompute(image, None)\n",
    "\n",
    "    return kp, des\n",
    "\n",
    "def signDetection(frame, queryKeypoints, queryDescriptions, feature_detection_algorithm, \n",
    "                  hessianThreshold = 400, MIN_MATCH_COUNT = 20, MIN_MATCH_PERCENTAGE = 0.18, \n",
    "                  MIN_MATCH = True):\n",
    "\n",
    "    '''\n",
    "    Input a frame and function will output a boolean. True = sign detected and \n",
    "    False = not detected.\n",
    "    \n",
    "    (Np.ndarray) frame\n",
    "    (STRING) feature_detection_algorithm = 'sift', 'surf', 'orb'.\n",
    "    (INT) hessianThreshold is basically number of key points. Smaller = more keypoints.\n",
    "    (INT) MIN_MATCH_COUNT is the minimum number of good matches for an object to be \n",
    "        considered the query image.\n",
    "    (FLOAT) MIN_MATCH_PERCENTAGE is the minimum match percentage for an object to be \n",
    "        considered the query image.\n",
    "    (BOOL) MIN_MATCH is a boolean. True means sign detectoin will use MIN_MATCH_COUNT. \n",
    "        False means sign detection will use MIN_MATCH_PERCENTAGE.\n",
    "    '''\n",
    "    kp_q = queryKeypoints\n",
    "    des_q = queryDescriptions\n",
    "    totalMatch = len(des_q) * 1.0\n",
    "\n",
    "\n",
    "    # Create SIFT, SURF, or ORB objects\n",
    "    kp_f, des_f = getKeypoints(frame, feature_detection_algorithm, hessianThreshold=hessianThreshold)\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "\n",
    "    if feature_detection_algorithm==\"orb\":\n",
    "        FLANN_INDEX_LSH = 6\n",
    "        index_params= dict(algorithm = FLANN_INDEX_LSH, table_number = 6, key_size = 12, multi_probe_level = 1)\n",
    "    else:\n",
    "        index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "        search_params = dict(checks=50)\n",
    "\n",
    "    # Matching keypoints\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    if (des_q is not None) and (des_f is not None) and des_f.shape[0] > 10:\n",
    "        matches = flann.knnMatch(des_q, des_f, k=2)\n",
    "        # print (\"des_q size: \" + str(des_q.shape))\n",
    "        # print (\"des_f size: \" + str(des_f.shape))\n",
    "    else:\n",
    "        matches = []\n",
    "\n",
    "    # store good matches via Lowe's ratio test\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    print (\"Match Percentage: \" + str('{0:.3g}'.format(100*(len(good)/totalMatch))) + \"%\")\n",
    "\n",
    "    # Checking if object is detected\n",
    "    if MIN_MATCH == False:\n",
    "        if len(good)/totalMatch > MIN_MATCH_PERCENTAGE:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        if len(good)>MIN_MATCH_COUNT:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "#################################################################################\n",
    "        \n",
    "#def draw_checkerboard_center(img):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "oneWaySign = cv2.imread(\"one_way.png\")\n",
    "oneWaySign = shrink(oneWaySign, 0.2)\n",
    "\n",
    "key_pts, descrip = getKeypoints(oneWaySign, \"surf\")\n",
    "\n",
    "checkerboard_check, sign_check = False, False\n",
    "\n",
    "\n",
    "while cv2.waitKey(200) & 0xFF != 27:\n",
    "    frame = video.read()[1]\n",
    "    if frame is not None:\n",
    "        frame = cv2.resize(frame, (640,480))  # Uncomment this line if issues arise\n",
    "        if signDetection(frame, key_pts, descrip, \"surf\"):\n",
    "            # do sth \n",
    "            if sign_check:\n",
    "                print(\"Sign\")\n",
    "                pass \n",
    "            else:\n",
    "                sign_check = True\n",
    "        else:\n",
    "            x, y = find_checkerboard_center(frame)\n",
    "            print(x, y)\n",
    "            if x != 0 and y != 0:\n",
    "                # do something\n",
    "                if checkerboard_check:\n",
    "                    print(\"Checkerboard\")\n",
    "                    pass \n",
    "                else:\n",
    "                    checkerboard_check = True\n",
    "            else:\n",
    "                pathSelection(frame, colorRange)\n",
    "                print(\"Line\")\n",
    "            \n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
